{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bank Churn Prediction</h1>\n",
    "\n",
    "<span style=\"color:blue\">Objective:</span></p>\n",
    "Given a Bank customer, build a neural network based classifier that can determine whether they will leave\n",
    "or not in the next 6 months.\n",
    "<p></p>\n",
    "<span style=\"color:blue\">Context:</span><br></br>\n",
    "Businesses like banks which provide service have to worry about problem of 'Churn' i.e. customers\n",
    "leaving and joining another service provider. It is important to understand which aspects of the service\n",
    "influence a customer's decision in this regard. Management can concentrate efforts on improvement of\n",
    "service, keeping in mind these priorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "### This dataset contains int64 values so i will need to change to float64 later because \n",
    "### this version of tensorflow requires it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>I will remove the unique fields in the dataset, or those that appears to be an id because they are not adding any value to the model, the output of our model is the Exited column, because we need to predict if the costumer is exited according to the input values that we will provide</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surname            2932\n",
       "CreditScore         460\n",
       "Geography             3\n",
       "Gender                2\n",
       "Age                  70\n",
       "Tenure               11\n",
       "Balance            6382\n",
       "NumOfProducts         4\n",
       "HasCrCard             2\n",
       "IsActiveMember        2\n",
       "EstimatedSalary    9999\n",
       "Exited                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can drop RowNumber and CustomerId because they are just unique\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cast this column as the output value, it has to be float64\n",
    "df['Exited'] = df['Exited'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It seems that we can convert the gender into an integer 0=Male, 1=Female\n",
    "df[\"Gender\"] = df[\"Gender\"].map({\"Female\": 1, \"Male\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the Geography i will need them in a numerical value but i won't add more columns to avoid more \n",
    "### compute procesing\n",
    "df[\"Geography\"] = df[\"Geography\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The interest of this exercise is to find if a customer is going to cancell the services or not, \n",
    "### so the target variable will be the column Exited\n",
    "Y = df.iloc[:,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The rest of the columns will be used as input variables\n",
    "X = df.iloc[:,1:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Spliting the dataset into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is a method used to standardize the range of independent variables or features of data. It is basically scaling all the dimensions to be even so that one independent variable does not dominate another. For example, bank account balance ranges from millions to 0, whereas gender is either 0 or 1. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n",
    "\n",
    "For this example i wil use normal zscale transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalizing X data\n",
    "zscale = StandardScaler()\n",
    "X_train = zscale.fit_transform(X_train)\n",
    "X_test = zscale.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>During the model creation process, i did try several approaches:</h3>\n",
    "\n",
    "<br><b>1) Intent 1</b>: 2 hidden layers, First layer with 10 neurons second layer with 5 neurons and using relu as activation function. The result was not good enough, having 80% of accurancy and a lot of errors</br>\n",
    "<br><b>2) Intent 2</b>: 3 hidden layers, First layer with 13 neurons, second layer with 8 neurons and third layer with 3 neurons, activation function remains relu and the number of epocs was changed to 100. The process was really slow and the accurancy was something no more than 86% which still is not good enough.</br>\n",
    "<br><b>3) Intent 3</b>: Same configuration as the second approach but this time i changed the activation function. I used a combination of selu and tanh for the layers. Same result and even more slower than the second approach.</br>\n",
    "<br><b>4) Intent 4</b>: This was the best configuration that i found, using 3 hidden layers, with 30 neurons each and using relu as an activation function the accurancy goes from 82% to 94%. Also i found that using more epocs we can improve this accuracy.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "model = Sequential()\n",
    "## First hidden layer\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='normal'))\n",
    "## Second hidden layer\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='normal'))\n",
    "## Third hidden layer\n",
    "model.add(Dense(30, activation='relu', kernel_initializer='normal'))\n",
    "### The outpunt layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer , metrics = ['accuracy','mae' , 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.1369 - accuracy: 0.8164 - mae: 0.2705 - mse: 0.1369 - val_loss: 0.1179 - val_accuracy: 0.8425 - val_mae: 0.2398 - val_mse: 0.1179\n",
      "Epoch 2/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.1133 - accuracy: 0.8485 - mae: 0.2317 - mse: 0.1133 - val_loss: 0.1107 - val_accuracy: 0.8488 - val_mae: 0.2309 - val_mse: 0.1107\n",
      "Epoch 3/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.8575 - mae: 0.2225 - mse: 0.1096 - val_loss: 0.1101 - val_accuracy: 0.8575 - val_mae: 0.2189 - val_mse: 0.1101\n",
      "Epoch 4/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.8599 - mae: 0.2184 - mse: 0.1067 - val_loss: 0.1088 - val_accuracy: 0.8562 - val_mae: 0.2198 - val_mse: 0.1088\n",
      "Epoch 5/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.8590 - mae: 0.2161 - mse: 0.1057 - val_loss: 0.1138 - val_accuracy: 0.8450 - val_mae: 0.2524 - val_mse: 0.1138\n",
      "Epoch 6/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.8601 - mae: 0.2135 - mse: 0.1046 - val_loss: 0.1099 - val_accuracy: 0.8650 - val_mae: 0.2187 - val_mse: 0.1099\n",
      "Epoch 7/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.8631 - mae: 0.2120 - mse: 0.1028 - val_loss: 0.1087 - val_accuracy: 0.8625 - val_mae: 0.2112 - val_mse: 0.1087\n",
      "Epoch 8/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.8617 - mae: 0.2062 - mse: 0.1020 - val_loss: 0.1097 - val_accuracy: 0.8550 - val_mae: 0.2160 - val_mse: 0.1097\n",
      "Epoch 9/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.8631 - mae: 0.2060 - mse: 0.1013 - val_loss: 0.1072 - val_accuracy: 0.8575 - val_mae: 0.2074 - val_mse: 0.1072\n",
      "Epoch 10/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.8633 - mae: 0.2058 - mse: 0.1008 - val_loss: 0.1085 - val_accuracy: 0.8525 - val_mae: 0.2133 - val_mse: 0.1085\n",
      "Epoch 11/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.8674 - mae: 0.2007 - mse: 0.0998 - val_loss: 0.1093 - val_accuracy: 0.8562 - val_mae: 0.2169 - val_mse: 0.1093\n",
      "Epoch 12/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.8676 - mae: 0.2020 - mse: 0.0993 - val_loss: 0.1084 - val_accuracy: 0.8462 - val_mae: 0.2050 - val_mse: 0.1084\n",
      "Epoch 13/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.8688 - mae: 0.2009 - mse: 0.0990 - val_loss: 0.1116 - val_accuracy: 0.8462 - val_mae: 0.2150 - val_mse: 0.1116\n",
      "Epoch 14/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.8674 - mae: 0.1982 - mse: 0.0985 - val_loss: 0.1111 - val_accuracy: 0.8525 - val_mae: 0.2185 - val_mse: 0.1111\n",
      "Epoch 15/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.8675 - mae: 0.1993 - mse: 0.0983 - val_loss: 0.1081 - val_accuracy: 0.8525 - val_mae: 0.2137 - val_mse: 0.1081\n",
      "Epoch 16/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.8676 - mae: 0.1961 - mse: 0.0975 - val_loss: 0.1073 - val_accuracy: 0.8562 - val_mae: 0.2196 - val_mse: 0.1073\n",
      "Epoch 17/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.8707 - mae: 0.1972 - mse: 0.0972 - val_loss: 0.1077 - val_accuracy: 0.8600 - val_mae: 0.1970 - val_mse: 0.1077\n",
      "Epoch 18/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.8703 - mae: 0.1970 - mse: 0.0974 - val_loss: 0.1093 - val_accuracy: 0.8512 - val_mae: 0.2116 - val_mse: 0.1093\n",
      "Epoch 19/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.8712 - mae: 0.1960 - mse: 0.0969 - val_loss: 0.1118 - val_accuracy: 0.8475 - val_mae: 0.2110 - val_mse: 0.1118\n",
      "Epoch 20/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.8692 - mae: 0.1944 - mse: 0.0959 - val_loss: 0.1115 - val_accuracy: 0.8525 - val_mae: 0.2158 - val_mse: 0.1115\n",
      "Epoch 21/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.8712 - mae: 0.1931 - mse: 0.0957 - val_loss: 0.1186 - val_accuracy: 0.8400 - val_mae: 0.2460 - val_mse: 0.1186\n",
      "Epoch 22/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.8710 - mae: 0.1944 - mse: 0.0957 - val_loss: 0.1135 - val_accuracy: 0.8538 - val_mae: 0.2217 - val_mse: 0.1135\n",
      "Epoch 23/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.8736 - mae: 0.1911 - mse: 0.0945 - val_loss: 0.1136 - val_accuracy: 0.8475 - val_mae: 0.2156 - val_mse: 0.1136\n",
      "Epoch 24/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.8728 - mae: 0.1938 - mse: 0.0949 - val_loss: 0.1139 - val_accuracy: 0.8525 - val_mae: 0.2166 - val_mse: 0.1139\n",
      "Epoch 25/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.8744 - mae: 0.1914 - mse: 0.0942 - val_loss: 0.1159 - val_accuracy: 0.8500 - val_mae: 0.1993 - val_mse: 0.1159\n",
      "Epoch 26/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.8726 - mae: 0.1916 - mse: 0.0946 - val_loss: 0.1141 - val_accuracy: 0.8550 - val_mae: 0.2101 - val_mse: 0.1141\n",
      "Epoch 27/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.8729 - mae: 0.1900 - mse: 0.0941 - val_loss: 0.1199 - val_accuracy: 0.8375 - val_mae: 0.2256 - val_mse: 0.1199\n",
      "Epoch 28/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.8740 - mae: 0.1929 - mse: 0.0943 - val_loss: 0.1172 - val_accuracy: 0.8425 - val_mae: 0.2150 - val_mse: 0.1172\n",
      "Epoch 29/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.8775 - mae: 0.1891 - mse: 0.0932 - val_loss: 0.1126 - val_accuracy: 0.8500 - val_mae: 0.2137 - val_mse: 0.1126\n",
      "Epoch 30/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.8783 - mae: 0.1887 - mse: 0.0927 - val_loss: 0.1147 - val_accuracy: 0.8475 - val_mae: 0.2164 - val_mse: 0.1147\n",
      "Epoch 31/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.8758 - mae: 0.1893 - mse: 0.0929 - val_loss: 0.1151 - val_accuracy: 0.8475 - val_mae: 0.2159 - val_mse: 0.1151\n",
      "Epoch 32/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.8762 - mae: 0.1869 - mse: 0.0927 - val_loss: 0.1133 - val_accuracy: 0.8550 - val_mae: 0.2189 - val_mse: 0.1133\n",
      "Epoch 33/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.8785 - mae: 0.1889 - mse: 0.0923 - val_loss: 0.1175 - val_accuracy: 0.8450 - val_mae: 0.2104 - val_mse: 0.1175\n",
      "Epoch 34/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.8749 - mae: 0.1875 - mse: 0.0922 - val_loss: 0.1179 - val_accuracy: 0.8450 - val_mae: 0.2271 - val_mse: 0.1179\n",
      "Epoch 35/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.8765 - mae: 0.1869 - mse: 0.0916 - val_loss: 0.1179 - val_accuracy: 0.8438 - val_mae: 0.2202 - val_mse: 0.1179\n",
      "Epoch 36/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.8801 - mae: 0.1850 - mse: 0.0909 - val_loss: 0.1167 - val_accuracy: 0.8438 - val_mae: 0.2154 - val_mse: 0.1167\n",
      "Epoch 37/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.8810 - mae: 0.1850 - mse: 0.0906 - val_loss: 0.1160 - val_accuracy: 0.8425 - val_mae: 0.2142 - val_mse: 0.1160\n",
      "Epoch 38/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.8767 - mae: 0.1846 - mse: 0.0907 - val_loss: 0.1196 - val_accuracy: 0.8488 - val_mae: 0.2165 - val_mse: 0.1196\n",
      "Epoch 39/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.8811 - mae: 0.1838 - mse: 0.0903 - val_loss: 0.1192 - val_accuracy: 0.8450 - val_mae: 0.2051 - val_mse: 0.1192\n",
      "Epoch 40/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.8826 - mae: 0.1847 - mse: 0.0900 - val_loss: 0.1220 - val_accuracy: 0.8387 - val_mae: 0.2167 - val_mse: 0.1220\n",
      "Epoch 41/400\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.8815 - mae: 0.1818 - mse: 0.0893 - val_loss: 0.1152 - val_accuracy: 0.8538 - val_mae: 0.2060 - val_mse: 0.1152\n",
      "Epoch 42/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.8788 - mae: 0.1832 - mse: 0.0898 - val_loss: 0.1186 - val_accuracy: 0.8475 - val_mae: 0.2079 - val_mse: 0.1186\n",
      "Epoch 43/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.8810 - mae: 0.1817 - mse: 0.0888 - val_loss: 0.1198 - val_accuracy: 0.8413 - val_mae: 0.2135 - val_mse: 0.1198\n",
      "Epoch 44/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.8803 - mae: 0.1803 - mse: 0.0886 - val_loss: 0.1208 - val_accuracy: 0.8462 - val_mae: 0.2142 - val_mse: 0.1208\n",
      "Epoch 45/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.8821 - mae: 0.1808 - mse: 0.0886 - val_loss: 0.1218 - val_accuracy: 0.8462 - val_mae: 0.2161 - val_mse: 0.1218\n",
      "Epoch 46/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.8812 - mae: 0.1805 - mse: 0.0880 - val_loss: 0.1204 - val_accuracy: 0.8413 - val_mae: 0.2128 - val_mse: 0.1204\n",
      "Epoch 47/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.8829 - mae: 0.1802 - mse: 0.0879 - val_loss: 0.1189 - val_accuracy: 0.8413 - val_mae: 0.2037 - val_mse: 0.1189\n",
      "Epoch 48/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.8843 - mae: 0.1763 - mse: 0.0875 - val_loss: 0.1233 - val_accuracy: 0.8462 - val_mae: 0.2294 - val_mse: 0.1233\n",
      "Epoch 49/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.8851 - mae: 0.1794 - mse: 0.0871 - val_loss: 0.1297 - val_accuracy: 0.8287 - val_mae: 0.2313 - val_mse: 0.1297\n",
      "Epoch 50/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.8860 - mae: 0.1789 - mse: 0.0869 - val_loss: 0.1233 - val_accuracy: 0.8425 - val_mae: 0.2221 - val_mse: 0.1233\n",
      "Epoch 51/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.8851 - mae: 0.1768 - mse: 0.0863 - val_loss: 0.1205 - val_accuracy: 0.8438 - val_mae: 0.2048 - val_mse: 0.1205\n",
      "Epoch 52/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.8843 - mae: 0.1786 - mse: 0.0869 - val_loss: 0.1247 - val_accuracy: 0.8313 - val_mae: 0.2068 - val_mse: 0.1247\n",
      "Epoch 53/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.8874 - mae: 0.1774 - mse: 0.0862 - val_loss: 0.1208 - val_accuracy: 0.8488 - val_mae: 0.2014 - val_mse: 0.1208\n",
      "Epoch 54/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.8856 - mae: 0.1739 - mse: 0.0856 - val_loss: 0.1217 - val_accuracy: 0.8475 - val_mae: 0.2181 - val_mse: 0.1217\n",
      "Epoch 55/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.8850 - mae: 0.1772 - mse: 0.0858 - val_loss: 0.1236 - val_accuracy: 0.8425 - val_mae: 0.2142 - val_mse: 0.1236\n",
      "Epoch 56/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.8885 - mae: 0.1753 - mse: 0.0849 - val_loss: 0.1239 - val_accuracy: 0.8425 - val_mae: 0.2115 - val_mse: 0.1239\n",
      "Epoch 57/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.8878 - mae: 0.1737 - mse: 0.0847 - val_loss: 0.1240 - val_accuracy: 0.8387 - val_mae: 0.2108 - val_mse: 0.1240\n",
      "Epoch 58/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.8906 - mae: 0.1719 - mse: 0.0838 - val_loss: 0.1284 - val_accuracy: 0.8413 - val_mae: 0.2154 - val_mse: 0.1284\n",
      "Epoch 59/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.8910 - mae: 0.1724 - mse: 0.0836 - val_loss: 0.1326 - val_accuracy: 0.8250 - val_mae: 0.2239 - val_mse: 0.1326\n",
      "Epoch 60/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.8876 - mae: 0.1749 - mse: 0.0845 - val_loss: 0.1233 - val_accuracy: 0.8413 - val_mae: 0.2146 - val_mse: 0.1233\n",
      "Epoch 61/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.8919 - mae: 0.1717 - mse: 0.0836 - val_loss: 0.1263 - val_accuracy: 0.8387 - val_mae: 0.2218 - val_mse: 0.1263\n",
      "Epoch 62/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.8892 - mae: 0.1730 - mse: 0.0835 - val_loss: 0.1218 - val_accuracy: 0.8438 - val_mae: 0.2089 - val_mse: 0.1218\n",
      "Epoch 63/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.8915 - mae: 0.1708 - mse: 0.0824 - val_loss: 0.1301 - val_accuracy: 0.8363 - val_mae: 0.2123 - val_mse: 0.1301\n",
      "Epoch 64/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.8904 - mae: 0.1687 - mse: 0.0828 - val_loss: 0.1245 - val_accuracy: 0.8363 - val_mae: 0.2124 - val_mse: 0.1245\n",
      "Epoch 65/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.8928 - mae: 0.1707 - mse: 0.0818 - val_loss: 0.1311 - val_accuracy: 0.8287 - val_mae: 0.2231 - val_mse: 0.1311\n",
      "Epoch 66/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.8911 - mae: 0.1684 - mse: 0.0819 - val_loss: 0.1277 - val_accuracy: 0.8363 - val_mae: 0.2180 - val_mse: 0.1277\n",
      "Epoch 67/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.8922 - mae: 0.1700 - mse: 0.0815 - val_loss: 0.1294 - val_accuracy: 0.8337 - val_mae: 0.2138 - val_mse: 0.1294\n",
      "Epoch 68/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.8926 - mae: 0.1683 - mse: 0.0813 - val_loss: 0.1272 - val_accuracy: 0.8363 - val_mae: 0.2130 - val_mse: 0.1272\n",
      "Epoch 69/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.8946 - mae: 0.1663 - mse: 0.0805 - val_loss: 0.1284 - val_accuracy: 0.8337 - val_mae: 0.2264 - val_mse: 0.1284\n",
      "Epoch 70/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.8931 - mae: 0.1681 - mse: 0.0809 - val_loss: 0.1310 - val_accuracy: 0.8350 - val_mae: 0.2245 - val_mse: 0.1310\n",
      "Epoch 71/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.8958 - mae: 0.1659 - mse: 0.0799 - val_loss: 0.1301 - val_accuracy: 0.8375 - val_mae: 0.2208 - val_mse: 0.1301\n",
      "Epoch 72/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.8954 - mae: 0.1656 - mse: 0.0797 - val_loss: 0.1257 - val_accuracy: 0.8387 - val_mae: 0.2112 - val_mse: 0.1257\n",
      "Epoch 73/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.8951 - mae: 0.1674 - mse: 0.0803 - val_loss: 0.1332 - val_accuracy: 0.8363 - val_mae: 0.2226 - val_mse: 0.1332\n",
      "Epoch 74/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.8954 - mae: 0.1644 - mse: 0.0793 - val_loss: 0.1317 - val_accuracy: 0.8337 - val_mae: 0.2157 - val_mse: 0.1317\n",
      "Epoch 75/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.8967 - mae: 0.1641 - mse: 0.0790 - val_loss: 0.1278 - val_accuracy: 0.8400 - val_mae: 0.2121 - val_mse: 0.1278\n",
      "Epoch 76/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.8972 - mae: 0.1650 - mse: 0.0793 - val_loss: 0.1311 - val_accuracy: 0.8350 - val_mae: 0.2177 - val_mse: 0.1311\n",
      "Epoch 77/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.8989 - mae: 0.1649 - mse: 0.0788 - val_loss: 0.1292 - val_accuracy: 0.8363 - val_mae: 0.2023 - val_mse: 0.1292\n",
      "Epoch 78/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.8979 - mae: 0.1638 - mse: 0.0785 - val_loss: 0.1287 - val_accuracy: 0.8413 - val_mae: 0.2161 - val_mse: 0.1287\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.8982 - mae: 0.1636 - mse: 0.0783 - val_loss: 0.1294 - val_accuracy: 0.8350 - val_mae: 0.2170 - val_mse: 0.1294\n",
      "Epoch 80/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.8982 - mae: 0.1641 - mse: 0.0786 - val_loss: 0.1296 - val_accuracy: 0.8363 - val_mae: 0.2155 - val_mse: 0.1296\n",
      "Epoch 81/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.8962 - mae: 0.1624 - mse: 0.0778 - val_loss: 0.1280 - val_accuracy: 0.8350 - val_mae: 0.2098 - val_mse: 0.1280\n",
      "Epoch 82/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9011 - mae: 0.1615 - mse: 0.0773 - val_loss: 0.1297 - val_accuracy: 0.8337 - val_mae: 0.2103 - val_mse: 0.1297\n",
      "Epoch 83/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.8974 - mae: 0.1619 - mse: 0.0775 - val_loss: 0.1293 - val_accuracy: 0.8425 - val_mae: 0.2168 - val_mse: 0.1293\n",
      "Epoch 84/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.8992 - mae: 0.1609 - mse: 0.0767 - val_loss: 0.1314 - val_accuracy: 0.8375 - val_mae: 0.2148 - val_mse: 0.1314\n",
      "Epoch 85/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9000 - mae: 0.1613 - mse: 0.0766 - val_loss: 0.1290 - val_accuracy: 0.8413 - val_mae: 0.2043 - val_mse: 0.1290\n",
      "Epoch 86/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.8976 - mae: 0.1625 - mse: 0.0773 - val_loss: 0.1275 - val_accuracy: 0.8387 - val_mae: 0.2129 - val_mse: 0.1275\n",
      "Epoch 87/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.8997 - mae: 0.1605 - mse: 0.0766 - val_loss: 0.1284 - val_accuracy: 0.8337 - val_mae: 0.2086 - val_mse: 0.1284\n",
      "Epoch 88/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9001 - mae: 0.1612 - mse: 0.0764 - val_loss: 0.1286 - val_accuracy: 0.8450 - val_mae: 0.2111 - val_mse: 0.1286\n",
      "Epoch 89/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9006 - mae: 0.1581 - mse: 0.0758 - val_loss: 0.1371 - val_accuracy: 0.8287 - val_mae: 0.2266 - val_mse: 0.1371\n",
      "Epoch 90/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9029 - mae: 0.1604 - mse: 0.0759 - val_loss: 0.1308 - val_accuracy: 0.8313 - val_mae: 0.2152 - val_mse: 0.1308\n",
      "Epoch 91/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9040 - mae: 0.1585 - mse: 0.0748 - val_loss: 0.1274 - val_accuracy: 0.8350 - val_mae: 0.2048 - val_mse: 0.1274\n",
      "Epoch 92/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9007 - mae: 0.1586 - mse: 0.0752 - val_loss: 0.1397 - val_accuracy: 0.8325 - val_mae: 0.2244 - val_mse: 0.1397\n",
      "Epoch 93/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9021 - mae: 0.1600 - mse: 0.0755 - val_loss: 0.1290 - val_accuracy: 0.8387 - val_mae: 0.2098 - val_mse: 0.1290\n",
      "Epoch 94/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9026 - mae: 0.1566 - mse: 0.0747 - val_loss: 0.1325 - val_accuracy: 0.8350 - val_mae: 0.2177 - val_mse: 0.1325\n",
      "Epoch 95/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9031 - mae: 0.1575 - mse: 0.0744 - val_loss: 0.1285 - val_accuracy: 0.8413 - val_mae: 0.2038 - val_mse: 0.1285\n",
      "Epoch 96/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9046 - mae: 0.1567 - mse: 0.0740 - val_loss: 0.1389 - val_accuracy: 0.8363 - val_mae: 0.2209 - val_mse: 0.1389\n",
      "Epoch 97/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9053 - mae: 0.1558 - mse: 0.0735 - val_loss: 0.1326 - val_accuracy: 0.8375 - val_mae: 0.2194 - val_mse: 0.1326\n",
      "Epoch 98/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9051 - mae: 0.1568 - mse: 0.0736 - val_loss: 0.1337 - val_accuracy: 0.8287 - val_mae: 0.2138 - val_mse: 0.1337\n",
      "Epoch 99/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9071 - mae: 0.1551 - mse: 0.0732 - val_loss: 0.1359 - val_accuracy: 0.8350 - val_mae: 0.2211 - val_mse: 0.1359\n",
      "Epoch 100/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9060 - mae: 0.1558 - mse: 0.0727 - val_loss: 0.1312 - val_accuracy: 0.8387 - val_mae: 0.2074 - val_mse: 0.1312\n",
      "Epoch 101/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9056 - mae: 0.1548 - mse: 0.0726 - val_loss: 0.1354 - val_accuracy: 0.8313 - val_mae: 0.2138 - val_mse: 0.1354\n",
      "Epoch 102/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9069 - mae: 0.1546 - mse: 0.0726 - val_loss: 0.1307 - val_accuracy: 0.8300 - val_mae: 0.2142 - val_mse: 0.1307\n",
      "Epoch 103/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9078 - mae: 0.1550 - mse: 0.0725 - val_loss: 0.1317 - val_accuracy: 0.8350 - val_mae: 0.2023 - val_mse: 0.1317\n",
      "Epoch 104/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9040 - mae: 0.1549 - mse: 0.0732 - val_loss: 0.1383 - val_accuracy: 0.8313 - val_mae: 0.2184 - val_mse: 0.1383\n",
      "Epoch 105/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9058 - mae: 0.1548 - mse: 0.0726 - val_loss: 0.1322 - val_accuracy: 0.8350 - val_mae: 0.2137 - val_mse: 0.1322\n",
      "Epoch 106/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9085 - mae: 0.1541 - mse: 0.0717 - val_loss: 0.1352 - val_accuracy: 0.8337 - val_mae: 0.2154 - val_mse: 0.1352\n",
      "Epoch 107/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9064 - mae: 0.1533 - mse: 0.0721 - val_loss: 0.1382 - val_accuracy: 0.8313 - val_mae: 0.2247 - val_mse: 0.1382\n",
      "Epoch 108/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9064 - mae: 0.1531 - mse: 0.0712 - val_loss: 0.1310 - val_accuracy: 0.8300 - val_mae: 0.2057 - val_mse: 0.1310\n",
      "Epoch 109/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9086 - mae: 0.1519 - mse: 0.0714 - val_loss: 0.1305 - val_accuracy: 0.8375 - val_mae: 0.2081 - val_mse: 0.1305\n",
      "Epoch 110/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9072 - mae: 0.1525 - mse: 0.0710 - val_loss: 0.1367 - val_accuracy: 0.8313 - val_mae: 0.2161 - val_mse: 0.1367\n",
      "Epoch 111/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9106 - mae: 0.1503 - mse: 0.0702 - val_loss: 0.1406 - val_accuracy: 0.8287 - val_mae: 0.2276 - val_mse: 0.1406\n",
      "Epoch 112/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9107 - mae: 0.1517 - mse: 0.0701 - val_loss: 0.1314 - val_accuracy: 0.8313 - val_mae: 0.2062 - val_mse: 0.1314\n",
      "Epoch 113/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9103 - mae: 0.1500 - mse: 0.0698 - val_loss: 0.1392 - val_accuracy: 0.8237 - val_mae: 0.2219 - val_mse: 0.1392\n",
      "Epoch 114/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9087 - mae: 0.1532 - mse: 0.0712 - val_loss: 0.1326 - val_accuracy: 0.8287 - val_mae: 0.2185 - val_mse: 0.1326\n",
      "Epoch 115/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.9106 - mae: 0.1498 - mse: 0.0694 - val_loss: 0.1342 - val_accuracy: 0.8363 - val_mae: 0.2165 - val_mse: 0.1342\n",
      "Epoch 116/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9110 - mae: 0.1508 - mse: 0.0703 - val_loss: 0.1328 - val_accuracy: 0.8313 - val_mae: 0.2130 - val_mse: 0.1328\n",
      "Epoch 117/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9125 - mae: 0.1499 - mse: 0.0690 - val_loss: 0.1423 - val_accuracy: 0.8300 - val_mae: 0.2297 - val_mse: 0.1423\n",
      "Epoch 118/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9106 - mae: 0.1504 - mse: 0.0693 - val_loss: 0.1377 - val_accuracy: 0.8325 - val_mae: 0.2142 - val_mse: 0.1377\n",
      "Epoch 119/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9137 - mae: 0.1490 - mse: 0.0691 - val_loss: 0.1396 - val_accuracy: 0.8200 - val_mae: 0.2172 - val_mse: 0.1396\n",
      "Epoch 120/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9118 - mae: 0.1488 - mse: 0.0688 - val_loss: 0.1374 - val_accuracy: 0.8275 - val_mae: 0.2140 - val_mse: 0.1374\n",
      "Epoch 121/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9111 - mae: 0.1499 - mse: 0.0687 - val_loss: 0.1349 - val_accuracy: 0.8313 - val_mae: 0.2147 - val_mse: 0.1349\n",
      "Epoch 122/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9131 - mae: 0.1484 - mse: 0.0682 - val_loss: 0.1389 - val_accuracy: 0.8313 - val_mae: 0.2199 - val_mse: 0.1389\n",
      "Epoch 123/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9126 - mae: 0.1489 - mse: 0.0682 - val_loss: 0.1349 - val_accuracy: 0.8275 - val_mae: 0.2077 - val_mse: 0.1349\n",
      "Epoch 124/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9132 - mae: 0.1471 - mse: 0.0679 - val_loss: 0.1324 - val_accuracy: 0.8275 - val_mae: 0.2204 - val_mse: 0.1324\n",
      "Epoch 125/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9139 - mae: 0.1482 - mse: 0.0678 - val_loss: 0.1373 - val_accuracy: 0.8275 - val_mae: 0.2231 - val_mse: 0.1373\n",
      "Epoch 126/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9140 - mae: 0.1479 - mse: 0.0673 - val_loss: 0.1333 - val_accuracy: 0.8313 - val_mae: 0.2110 - val_mse: 0.1333\n",
      "Epoch 127/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9129 - mae: 0.1469 - mse: 0.0676 - val_loss: 0.1374 - val_accuracy: 0.8213 - val_mae: 0.2268 - val_mse: 0.1374\n",
      "Epoch 128/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9144 - mae: 0.1472 - mse: 0.0671 - val_loss: 0.1337 - val_accuracy: 0.8275 - val_mae: 0.2100 - val_mse: 0.1337\n",
      "Epoch 129/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9128 - mae: 0.1476 - mse: 0.0678 - val_loss: 0.1355 - val_accuracy: 0.8275 - val_mae: 0.2119 - val_mse: 0.1355\n",
      "Epoch 130/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9135 - mae: 0.1462 - mse: 0.0668 - val_loss: 0.1339 - val_accuracy: 0.8313 - val_mae: 0.2144 - val_mse: 0.1339\n",
      "Epoch 131/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9153 - mae: 0.1473 - mse: 0.0675 - val_loss: 0.1379 - val_accuracy: 0.8350 - val_mae: 0.2130 - val_mse: 0.1379\n",
      "Epoch 132/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9165 - mae: 0.1440 - mse: 0.0661 - val_loss: 0.1418 - val_accuracy: 0.8287 - val_mae: 0.2303 - val_mse: 0.1418\n",
      "Epoch 133/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9157 - mae: 0.1461 - mse: 0.0666 - val_loss: 0.1384 - val_accuracy: 0.8237 - val_mae: 0.2193 - val_mse: 0.1384\n",
      "Epoch 134/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9150 - mae: 0.1462 - mse: 0.0665 - val_loss: 0.1394 - val_accuracy: 0.8263 - val_mae: 0.2179 - val_mse: 0.1394\n",
      "Epoch 135/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9154 - mae: 0.1451 - mse: 0.0661 - val_loss: 0.1397 - val_accuracy: 0.8237 - val_mae: 0.2195 - val_mse: 0.1397\n",
      "Epoch 136/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9182 - mae: 0.1450 - mse: 0.0654 - val_loss: 0.1350 - val_accuracy: 0.8250 - val_mae: 0.2103 - val_mse: 0.1350\n",
      "Epoch 137/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9168 - mae: 0.1451 - mse: 0.0659 - val_loss: 0.1330 - val_accuracy: 0.8313 - val_mae: 0.2092 - val_mse: 0.1330\n",
      "Epoch 138/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9179 - mae: 0.1442 - mse: 0.0649 - val_loss: 0.1405 - val_accuracy: 0.8163 - val_mae: 0.2207 - val_mse: 0.1405\n",
      "Epoch 139/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9163 - mae: 0.1434 - mse: 0.0655 - val_loss: 0.1401 - val_accuracy: 0.8237 - val_mae: 0.2201 - val_mse: 0.1401\n",
      "Epoch 140/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9160 - mae: 0.1451 - mse: 0.0653 - val_loss: 0.1385 - val_accuracy: 0.8237 - val_mae: 0.2212 - val_mse: 0.1385\n",
      "Epoch 141/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9187 - mae: 0.1439 - mse: 0.0650 - val_loss: 0.1389 - val_accuracy: 0.8300 - val_mae: 0.2121 - val_mse: 0.1389\n",
      "Epoch 142/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9204 - mae: 0.1434 - mse: 0.0648 - val_loss: 0.1377 - val_accuracy: 0.8250 - val_mae: 0.2154 - val_mse: 0.1377\n",
      "Epoch 143/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9197 - mae: 0.1420 - mse: 0.0641 - val_loss: 0.1425 - val_accuracy: 0.8287 - val_mae: 0.2247 - val_mse: 0.1425\n",
      "Epoch 144/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9176 - mae: 0.1436 - mse: 0.0650 - val_loss: 0.1389 - val_accuracy: 0.8263 - val_mae: 0.2137 - val_mse: 0.1389\n",
      "Epoch 145/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9203 - mae: 0.1438 - mse: 0.0642 - val_loss: 0.1451 - val_accuracy: 0.8175 - val_mae: 0.2246 - val_mse: 0.1451\n",
      "Epoch 146/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9218 - mae: 0.1408 - mse: 0.0635 - val_loss: 0.1410 - val_accuracy: 0.8250 - val_mae: 0.2192 - val_mse: 0.1410\n",
      "Epoch 147/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9200 - mae: 0.1429 - mse: 0.0640 - val_loss: 0.1391 - val_accuracy: 0.8200 - val_mae: 0.2137 - val_mse: 0.1391\n",
      "Epoch 148/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9190 - mae: 0.1423 - mse: 0.0642 - val_loss: 0.1418 - val_accuracy: 0.8237 - val_mae: 0.2250 - val_mse: 0.1418\n",
      "Epoch 149/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9203 - mae: 0.1431 - mse: 0.0637 - val_loss: 0.1433 - val_accuracy: 0.8200 - val_mae: 0.2260 - val_mse: 0.1433\n",
      "Epoch 150/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9214 - mae: 0.1408 - mse: 0.0631 - val_loss: 0.1439 - val_accuracy: 0.8213 - val_mae: 0.2202 - val_mse: 0.1439\n",
      "Epoch 151/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9197 - mae: 0.1438 - mse: 0.0644 - val_loss: 0.1367 - val_accuracy: 0.8325 - val_mae: 0.2071 - val_mse: 0.1367\n",
      "Epoch 152/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9185 - mae: 0.1417 - mse: 0.0642 - val_loss: 0.1403 - val_accuracy: 0.8213 - val_mae: 0.2210 - val_mse: 0.1403\n",
      "Epoch 153/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9201 - mae: 0.1421 - mse: 0.0632 - val_loss: 0.1454 - val_accuracy: 0.8225 - val_mae: 0.2219 - val_mse: 0.1454\n",
      "Epoch 154/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9185 - mae: 0.1405 - mse: 0.0634 - val_loss: 0.1396 - val_accuracy: 0.8225 - val_mae: 0.2203 - val_mse: 0.1396\n",
      "Epoch 155/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9215 - mae: 0.1402 - mse: 0.0629 - val_loss: 0.1486 - val_accuracy: 0.8213 - val_mae: 0.2307 - val_mse: 0.1486\n",
      "Epoch 156/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9187 - mae: 0.1413 - mse: 0.0635 - val_loss: 0.1359 - val_accuracy: 0.8200 - val_mae: 0.2142 - val_mse: 0.1359\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9218 - mae: 0.1415 - mse: 0.0631 - val_loss: 0.1438 - val_accuracy: 0.8263 - val_mae: 0.2219 - val_mse: 0.1438\n",
      "Epoch 158/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9222 - mae: 0.1404 - mse: 0.0625 - val_loss: 0.1408 - val_accuracy: 0.8225 - val_mae: 0.2247 - val_mse: 0.1408\n",
      "Epoch 159/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9231 - mae: 0.1411 - mse: 0.0626 - val_loss: 0.1538 - val_accuracy: 0.8200 - val_mae: 0.2355 - val_mse: 0.1538\n",
      "Epoch 160/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9221 - mae: 0.1402 - mse: 0.0623 - val_loss: 0.1419 - val_accuracy: 0.8250 - val_mae: 0.2256 - val_mse: 0.1419\n",
      "Epoch 161/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9239 - mae: 0.1397 - mse: 0.0620 - val_loss: 0.1403 - val_accuracy: 0.8163 - val_mae: 0.2233 - val_mse: 0.1403\n",
      "Epoch 162/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9231 - mae: 0.1414 - mse: 0.0621 - val_loss: 0.1479 - val_accuracy: 0.8213 - val_mae: 0.2266 - val_mse: 0.1479\n",
      "Epoch 163/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9215 - mae: 0.1387 - mse: 0.0619 - val_loss: 0.1439 - val_accuracy: 0.8200 - val_mae: 0.2227 - val_mse: 0.1439\n",
      "Epoch 164/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9264 - mae: 0.1379 - mse: 0.0607 - val_loss: 0.1426 - val_accuracy: 0.8200 - val_mae: 0.2240 - val_mse: 0.1426\n",
      "Epoch 165/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9254 - mae: 0.1378 - mse: 0.0608 - val_loss: 0.1442 - val_accuracy: 0.8250 - val_mae: 0.2190 - val_mse: 0.1442\n",
      "Epoch 166/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9229 - mae: 0.1388 - mse: 0.0614 - val_loss: 0.1422 - val_accuracy: 0.8287 - val_mae: 0.2169 - val_mse: 0.1422\n",
      "Epoch 167/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9239 - mae: 0.1392 - mse: 0.0616 - val_loss: 0.1346 - val_accuracy: 0.8287 - val_mae: 0.2057 - val_mse: 0.1346\n",
      "Epoch 168/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9249 - mae: 0.1389 - mse: 0.0616 - val_loss: 0.1475 - val_accuracy: 0.8163 - val_mae: 0.2248 - val_mse: 0.1475\n",
      "Epoch 169/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9246 - mae: 0.1383 - mse: 0.0611 - val_loss: 0.1513 - val_accuracy: 0.8113 - val_mae: 0.2313 - val_mse: 0.1513\n",
      "Epoch 170/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9261 - mae: 0.1389 - mse: 0.0611 - val_loss: 0.1437 - val_accuracy: 0.8200 - val_mae: 0.2217 - val_mse: 0.1437\n",
      "Epoch 171/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9250 - mae: 0.1396 - mse: 0.0616 - val_loss: 0.1511 - val_accuracy: 0.8150 - val_mae: 0.2200 - val_mse: 0.1511\n",
      "Epoch 172/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9257 - mae: 0.1367 - mse: 0.0602 - val_loss: 0.1459 - val_accuracy: 0.8163 - val_mae: 0.2210 - val_mse: 0.1459\n",
      "Epoch 173/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9258 - mae: 0.1375 - mse: 0.0603 - val_loss: 0.1540 - val_accuracy: 0.8100 - val_mae: 0.2343 - val_mse: 0.1540\n",
      "Epoch 174/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9287 - mae: 0.1360 - mse: 0.0596 - val_loss: 0.1401 - val_accuracy: 0.8263 - val_mae: 0.2155 - val_mse: 0.1401\n",
      "Epoch 175/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9258 - mae: 0.1369 - mse: 0.0601 - val_loss: 0.1468 - val_accuracy: 0.8275 - val_mae: 0.2294 - val_mse: 0.1468\n",
      "Epoch 176/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9274 - mae: 0.1391 - mse: 0.0602 - val_loss: 0.1469 - val_accuracy: 0.8175 - val_mae: 0.2180 - val_mse: 0.1469\n",
      "Epoch 177/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9256 - mae: 0.1365 - mse: 0.0607 - val_loss: 0.1460 - val_accuracy: 0.8225 - val_mae: 0.2228 - val_mse: 0.1460\n",
      "Epoch 178/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9247 - mae: 0.1365 - mse: 0.0602 - val_loss: 0.1444 - val_accuracy: 0.8250 - val_mae: 0.2226 - val_mse: 0.1444\n",
      "Epoch 179/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9278 - mae: 0.1376 - mse: 0.0600 - val_loss: 0.1394 - val_accuracy: 0.8300 - val_mae: 0.2141 - val_mse: 0.1394\n",
      "Epoch 180/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9269 - mae: 0.1355 - mse: 0.0595 - val_loss: 0.1448 - val_accuracy: 0.8200 - val_mae: 0.2209 - val_mse: 0.1448\n",
      "Epoch 181/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9278 - mae: 0.1370 - mse: 0.0595 - val_loss: 0.1481 - val_accuracy: 0.8137 - val_mae: 0.2222 - val_mse: 0.1481\n",
      "Epoch 182/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9278 - mae: 0.1345 - mse: 0.0590 - val_loss: 0.1404 - val_accuracy: 0.8287 - val_mae: 0.2107 - val_mse: 0.1404\n",
      "Epoch 183/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9263 - mae: 0.1368 - mse: 0.0595 - val_loss: 0.1418 - val_accuracy: 0.8213 - val_mae: 0.2135 - val_mse: 0.1418\n",
      "Epoch 184/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9283 - mae: 0.1351 - mse: 0.0589 - val_loss: 0.1409 - val_accuracy: 0.8187 - val_mae: 0.2141 - val_mse: 0.1409\n",
      "Epoch 185/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9283 - mae: 0.1360 - mse: 0.0591 - val_loss: 0.1480 - val_accuracy: 0.8237 - val_mae: 0.2213 - val_mse: 0.1480\n",
      "Epoch 186/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9299 - mae: 0.1353 - mse: 0.0588 - val_loss: 0.1436 - val_accuracy: 0.8225 - val_mae: 0.2235 - val_mse: 0.1436\n",
      "Epoch 187/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9283 - mae: 0.1356 - mse: 0.0586 - val_loss: 0.1452 - val_accuracy: 0.8175 - val_mae: 0.2191 - val_mse: 0.1452\n",
      "Epoch 188/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9274 - mae: 0.1344 - mse: 0.0587 - val_loss: 0.1561 - val_accuracy: 0.8163 - val_mae: 0.2321 - val_mse: 0.1561\n",
      "Epoch 189/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9290 - mae: 0.1349 - mse: 0.0589 - val_loss: 0.1563 - val_accuracy: 0.8087 - val_mae: 0.2341 - val_mse: 0.1563\n",
      "Epoch 190/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9261 - mae: 0.1348 - mse: 0.0587 - val_loss: 0.1530 - val_accuracy: 0.8200 - val_mae: 0.2251 - val_mse: 0.1530\n",
      "Epoch 191/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9289 - mae: 0.1358 - mse: 0.0589 - val_loss: 0.1514 - val_accuracy: 0.8175 - val_mae: 0.2261 - val_mse: 0.1514\n",
      "Epoch 192/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9308 - mae: 0.1344 - mse: 0.0581 - val_loss: 0.1438 - val_accuracy: 0.8213 - val_mae: 0.2127 - val_mse: 0.1438\n",
      "Epoch 193/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9301 - mae: 0.1353 - mse: 0.0587 - val_loss: 0.1390 - val_accuracy: 0.8300 - val_mae: 0.2108 - val_mse: 0.1390\n",
      "Epoch 194/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9310 - mae: 0.1342 - mse: 0.0580 - val_loss: 0.1519 - val_accuracy: 0.8200 - val_mae: 0.2234 - val_mse: 0.1519\n",
      "Epoch 195/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9294 - mae: 0.1339 - mse: 0.0578 - val_loss: 0.1451 - val_accuracy: 0.8225 - val_mae: 0.2159 - val_mse: 0.1451\n",
      "Epoch 196/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9294 - mae: 0.1334 - mse: 0.0577 - val_loss: 0.1407 - val_accuracy: 0.8325 - val_mae: 0.2155 - val_mse: 0.1407\n",
      "Epoch 197/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9294 - mae: 0.1342 - mse: 0.0578 - val_loss: 0.1542 - val_accuracy: 0.8213 - val_mae: 0.2289 - val_mse: 0.1542\n",
      "Epoch 198/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9301 - mae: 0.1323 - mse: 0.0569 - val_loss: 0.1541 - val_accuracy: 0.8137 - val_mae: 0.2247 - val_mse: 0.1541\n",
      "Epoch 199/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9311 - mae: 0.1331 - mse: 0.0572 - val_loss: 0.1528 - val_accuracy: 0.8200 - val_mae: 0.2284 - val_mse: 0.1528\n",
      "Epoch 200/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9313 - mae: 0.1325 - mse: 0.0569 - val_loss: 0.1519 - val_accuracy: 0.8163 - val_mae: 0.2278 - val_mse: 0.1519\n",
      "Epoch 201/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9318 - mae: 0.1339 - mse: 0.0576 - val_loss: 0.1494 - val_accuracy: 0.8213 - val_mae: 0.2246 - val_mse: 0.1494\n",
      "Epoch 202/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9293 - mae: 0.1340 - mse: 0.0577 - val_loss: 0.1503 - val_accuracy: 0.8213 - val_mae: 0.2193 - val_mse: 0.1503\n",
      "Epoch 203/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9285 - mae: 0.1335 - mse: 0.0573 - val_loss: 0.1600 - val_accuracy: 0.8100 - val_mae: 0.2279 - val_mse: 0.1600\n",
      "Epoch 204/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9329 - mae: 0.1317 - mse: 0.0564 - val_loss: 0.1549 - val_accuracy: 0.8175 - val_mae: 0.2214 - val_mse: 0.1549\n",
      "Epoch 205/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9313 - mae: 0.1311 - mse: 0.0567 - val_loss: 0.1551 - val_accuracy: 0.8137 - val_mae: 0.2313 - val_mse: 0.1551\n",
      "Epoch 206/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9307 - mae: 0.1326 - mse: 0.0571 - val_loss: 0.1516 - val_accuracy: 0.8150 - val_mae: 0.2295 - val_mse: 0.1516\n",
      "Epoch 207/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9318 - mae: 0.1320 - mse: 0.0562 - val_loss: 0.1476 - val_accuracy: 0.8225 - val_mae: 0.2243 - val_mse: 0.1476\n",
      "Epoch 208/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9314 - mae: 0.1316 - mse: 0.0564 - val_loss: 0.1511 - val_accuracy: 0.8200 - val_mae: 0.2262 - val_mse: 0.1511\n",
      "Epoch 209/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9307 - mae: 0.1336 - mse: 0.0573 - val_loss: 0.1548 - val_accuracy: 0.8163 - val_mae: 0.2348 - val_mse: 0.1548\n",
      "Epoch 210/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9313 - mae: 0.1327 - mse: 0.0565 - val_loss: 0.1533 - val_accuracy: 0.8150 - val_mae: 0.2254 - val_mse: 0.1533\n",
      "Epoch 211/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9297 - mae: 0.1337 - mse: 0.0577 - val_loss: 0.1521 - val_accuracy: 0.8175 - val_mae: 0.2263 - val_mse: 0.1521\n",
      "Epoch 212/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9315 - mae: 0.1309 - mse: 0.0556 - val_loss: 0.1562 - val_accuracy: 0.8163 - val_mae: 0.2270 - val_mse: 0.1562\n",
      "Epoch 213/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9311 - mae: 0.1311 - mse: 0.0563 - val_loss: 0.1514 - val_accuracy: 0.8125 - val_mae: 0.2245 - val_mse: 0.1514\n",
      "Epoch 214/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9332 - mae: 0.1302 - mse: 0.0552 - val_loss: 0.1519 - val_accuracy: 0.8175 - val_mae: 0.2219 - val_mse: 0.1519\n",
      "Epoch 215/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9318 - mae: 0.1298 - mse: 0.0551 - val_loss: 0.1527 - val_accuracy: 0.8300 - val_mae: 0.2206 - val_mse: 0.1527\n",
      "Epoch 216/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9331 - mae: 0.1295 - mse: 0.0550 - val_loss: 0.1573 - val_accuracy: 0.8113 - val_mae: 0.2298 - val_mse: 0.1573\n",
      "Epoch 217/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9322 - mae: 0.1311 - mse: 0.0557 - val_loss: 0.1569 - val_accuracy: 0.8137 - val_mae: 0.2312 - val_mse: 0.1569\n",
      "Epoch 218/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9325 - mae: 0.1319 - mse: 0.0556 - val_loss: 0.1614 - val_accuracy: 0.8137 - val_mae: 0.2348 - val_mse: 0.1614\n",
      "Epoch 219/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9335 - mae: 0.1305 - mse: 0.0548 - val_loss: 0.1551 - val_accuracy: 0.8137 - val_mae: 0.2275 - val_mse: 0.1551\n",
      "Epoch 220/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9349 - mae: 0.1297 - mse: 0.0549 - val_loss: 0.1543 - val_accuracy: 0.8250 - val_mae: 0.2248 - val_mse: 0.1543\n",
      "Epoch 221/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9333 - mae: 0.1317 - mse: 0.0559 - val_loss: 0.1577 - val_accuracy: 0.8175 - val_mae: 0.2255 - val_mse: 0.1577\n",
      "Epoch 222/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9337 - mae: 0.1285 - mse: 0.0547 - val_loss: 0.1469 - val_accuracy: 0.8225 - val_mae: 0.2214 - val_mse: 0.1469\n",
      "Epoch 223/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9332 - mae: 0.1302 - mse: 0.0554 - val_loss: 0.1546 - val_accuracy: 0.8213 - val_mae: 0.2237 - val_mse: 0.1546\n",
      "Epoch 224/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9337 - mae: 0.1289 - mse: 0.0543 - val_loss: 0.1552 - val_accuracy: 0.8237 - val_mae: 0.2234 - val_mse: 0.1552\n",
      "Epoch 225/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9363 - mae: 0.1296 - mse: 0.0543 - val_loss: 0.1575 - val_accuracy: 0.8113 - val_mae: 0.2268 - val_mse: 0.1575\n",
      "Epoch 226/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9361 - mae: 0.1297 - mse: 0.0548 - val_loss: 0.1543 - val_accuracy: 0.8187 - val_mae: 0.2258 - val_mse: 0.1543\n",
      "Epoch 227/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9364 - mae: 0.1289 - mse: 0.0540 - val_loss: 0.1614 - val_accuracy: 0.8163 - val_mae: 0.2345 - val_mse: 0.1614\n",
      "Epoch 228/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9343 - mae: 0.1295 - mse: 0.0546 - val_loss: 0.1568 - val_accuracy: 0.8200 - val_mae: 0.2208 - val_mse: 0.1568\n",
      "Epoch 229/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9331 - mae: 0.1302 - mse: 0.0546 - val_loss: 0.1634 - val_accuracy: 0.8150 - val_mae: 0.2285 - val_mse: 0.1634\n",
      "Epoch 230/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9353 - mae: 0.1287 - mse: 0.0539 - val_loss: 0.1528 - val_accuracy: 0.8175 - val_mae: 0.2255 - val_mse: 0.1528\n",
      "Epoch 231/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9365 - mae: 0.1289 - mse: 0.0538 - val_loss: 0.1627 - val_accuracy: 0.8187 - val_mae: 0.2320 - val_mse: 0.1627\n",
      "Epoch 232/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9344 - mae: 0.1300 - mse: 0.0551 - val_loss: 0.1628 - val_accuracy: 0.8075 - val_mae: 0.2294 - val_mse: 0.1628\n",
      "Epoch 233/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9356 - mae: 0.1297 - mse: 0.0544 - val_loss: 0.1625 - val_accuracy: 0.8137 - val_mae: 0.2299 - val_mse: 0.1625\n",
      "Epoch 234/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9365 - mae: 0.1295 - mse: 0.0536 - val_loss: 0.1534 - val_accuracy: 0.8237 - val_mae: 0.2203 - val_mse: 0.1534\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.9350 - mae: 0.1285 - mse: 0.0539 - val_loss: 0.1569 - val_accuracy: 0.8187 - val_mae: 0.2264 - val_mse: 0.1569\n",
      "Epoch 236/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9369 - mae: 0.1301 - mse: 0.0544 - val_loss: 0.1679 - val_accuracy: 0.8087 - val_mae: 0.2338 - val_mse: 0.1679\n",
      "Epoch 237/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.9364 - mae: 0.1287 - mse: 0.0538 - val_loss: 0.1592 - val_accuracy: 0.8213 - val_mae: 0.2340 - val_mse: 0.1592\n",
      "Epoch 238/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9346 - mae: 0.1300 - mse: 0.0537 - val_loss: 0.1516 - val_accuracy: 0.8163 - val_mae: 0.2191 - val_mse: 0.1516\n",
      "Epoch 239/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9361 - mae: 0.1273 - mse: 0.0535 - val_loss: 0.1556 - val_accuracy: 0.8163 - val_mae: 0.2295 - val_mse: 0.1556\n",
      "Epoch 240/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9374 - mae: 0.1281 - mse: 0.0529 - val_loss: 0.1574 - val_accuracy: 0.8150 - val_mae: 0.2275 - val_mse: 0.1574\n",
      "Epoch 241/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.9369 - mae: 0.1286 - mse: 0.0536 - val_loss: 0.1568 - val_accuracy: 0.8175 - val_mae: 0.2267 - val_mse: 0.1568\n",
      "Epoch 242/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9360 - mae: 0.1263 - mse: 0.0526 - val_loss: 0.1561 - val_accuracy: 0.8275 - val_mae: 0.2312 - val_mse: 0.1561\n",
      "Epoch 243/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9387 - mae: 0.1280 - mse: 0.0530 - val_loss: 0.1635 - val_accuracy: 0.8113 - val_mae: 0.2331 - val_mse: 0.1635\n",
      "Epoch 244/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9374 - mae: 0.1274 - mse: 0.0532 - val_loss: 0.1532 - val_accuracy: 0.8200 - val_mae: 0.2265 - val_mse: 0.1532\n",
      "Epoch 245/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9368 - mae: 0.1294 - mse: 0.0535 - val_loss: 0.1511 - val_accuracy: 0.8263 - val_mae: 0.2209 - val_mse: 0.1511\n",
      "Epoch 246/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9343 - mae: 0.1299 - mse: 0.0540 - val_loss: 0.1658 - val_accuracy: 0.8100 - val_mae: 0.2337 - val_mse: 0.1658\n",
      "Epoch 247/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9371 - mae: 0.1284 - mse: 0.0525 - val_loss: 0.1500 - val_accuracy: 0.8225 - val_mae: 0.2148 - val_mse: 0.1500\n",
      "Epoch 248/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0521 - accuracy: 0.9393 - mae: 0.1266 - mse: 0.0521 - val_loss: 0.1713 - val_accuracy: 0.8075 - val_mae: 0.2458 - val_mse: 0.1713\n",
      "Epoch 249/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9351 - mae: 0.1278 - mse: 0.0530 - val_loss: 0.1720 - val_accuracy: 0.8125 - val_mae: 0.2377 - val_mse: 0.1720\n",
      "Epoch 250/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9397 - mae: 0.1271 - mse: 0.0524 - val_loss: 0.1702 - val_accuracy: 0.8125 - val_mae: 0.2373 - val_mse: 0.1702\n",
      "Epoch 251/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9378 - mae: 0.1276 - mse: 0.0531 - val_loss: 0.1687 - val_accuracy: 0.8100 - val_mae: 0.2381 - val_mse: 0.1687\n",
      "Epoch 252/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9386 - mae: 0.1277 - mse: 0.0522 - val_loss: 0.1566 - val_accuracy: 0.8200 - val_mae: 0.2249 - val_mse: 0.1566\n",
      "Epoch 253/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9379 - mae: 0.1269 - mse: 0.0523 - val_loss: 0.1518 - val_accuracy: 0.8187 - val_mae: 0.2241 - val_mse: 0.1518\n",
      "Epoch 254/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9406 - mae: 0.1262 - mse: 0.0514 - val_loss: 0.1663 - val_accuracy: 0.8063 - val_mae: 0.2400 - val_mse: 0.1663\n",
      "Epoch 255/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9385 - mae: 0.1257 - mse: 0.0520 - val_loss: 0.1728 - val_accuracy: 0.8063 - val_mae: 0.2392 - val_mse: 0.1728\n",
      "Epoch 256/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9374 - mae: 0.1275 - mse: 0.0532 - val_loss: 0.1557 - val_accuracy: 0.8187 - val_mae: 0.2261 - val_mse: 0.1557\n",
      "Epoch 257/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9396 - mae: 0.1252 - mse: 0.0509 - val_loss: 0.1577 - val_accuracy: 0.8137 - val_mae: 0.2362 - val_mse: 0.1577\n",
      "Epoch 258/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9394 - mae: 0.1269 - mse: 0.0514 - val_loss: 0.1658 - val_accuracy: 0.8137 - val_mae: 0.2324 - val_mse: 0.1658\n",
      "Epoch 259/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9401 - mae: 0.1264 - mse: 0.0514 - val_loss: 0.1582 - val_accuracy: 0.8187 - val_mae: 0.2248 - val_mse: 0.1582\n",
      "Epoch 260/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9390 - mae: 0.1269 - mse: 0.0519 - val_loss: 0.1639 - val_accuracy: 0.8137 - val_mae: 0.2313 - val_mse: 0.1639\n",
      "Epoch 261/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9401 - mae: 0.1251 - mse: 0.0515 - val_loss: 0.1720 - val_accuracy: 0.8050 - val_mae: 0.2463 - val_mse: 0.1720\n",
      "Epoch 262/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9383 - mae: 0.1257 - mse: 0.0515 - val_loss: 0.1631 - val_accuracy: 0.8075 - val_mae: 0.2313 - val_mse: 0.1631\n",
      "Epoch 263/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9393 - mae: 0.1262 - mse: 0.0518 - val_loss: 0.1567 - val_accuracy: 0.8175 - val_mae: 0.2269 - val_mse: 0.1567\n",
      "Epoch 264/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9367 - mae: 0.1279 - mse: 0.0530 - val_loss: 0.1676 - val_accuracy: 0.8075 - val_mae: 0.2392 - val_mse: 0.1676\n",
      "Epoch 265/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9400 - mae: 0.1270 - mse: 0.0519 - val_loss: 0.1577 - val_accuracy: 0.8163 - val_mae: 0.2295 - val_mse: 0.1577\n",
      "Epoch 266/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9399 - mae: 0.1242 - mse: 0.0509 - val_loss: 0.1564 - val_accuracy: 0.8187 - val_mae: 0.2296 - val_mse: 0.1564\n",
      "Epoch 267/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0512 - accuracy: 0.9404 - mae: 0.1262 - mse: 0.0512 - val_loss: 0.1722 - val_accuracy: 0.8100 - val_mae: 0.2422 - val_mse: 0.1722\n",
      "Epoch 268/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9407 - mae: 0.1263 - mse: 0.0515 - val_loss: 0.1595 - val_accuracy: 0.8175 - val_mae: 0.2276 - val_mse: 0.1595\n",
      "Epoch 269/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9406 - mae: 0.1260 - mse: 0.0511 - val_loss: 0.1696 - val_accuracy: 0.8187 - val_mae: 0.2377 - val_mse: 0.1696\n",
      "Epoch 270/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.9406 - mae: 0.1243 - mse: 0.0505 - val_loss: 0.1676 - val_accuracy: 0.8125 - val_mae: 0.2384 - val_mse: 0.1676\n",
      "Epoch 271/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9417 - mae: 0.1269 - mse: 0.0520 - val_loss: 0.1735 - val_accuracy: 0.8063 - val_mae: 0.2378 - val_mse: 0.1735\n",
      "Epoch 272/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9404 - mae: 0.1259 - mse: 0.0512 - val_loss: 0.1689 - val_accuracy: 0.8175 - val_mae: 0.2318 - val_mse: 0.1689\n",
      "Epoch 273/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9410 - mae: 0.1238 - mse: 0.0507 - val_loss: 0.1646 - val_accuracy: 0.8113 - val_mae: 0.2337 - val_mse: 0.1646\n",
      "Epoch 274/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9413 - mae: 0.1252 - mse: 0.0511 - val_loss: 0.1629 - val_accuracy: 0.8150 - val_mae: 0.2357 - val_mse: 0.1629\n",
      "Epoch 275/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9404 - mae: 0.1250 - mse: 0.0507 - val_loss: 0.1695 - val_accuracy: 0.8037 - val_mae: 0.2403 - val_mse: 0.1695\n",
      "Epoch 276/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9422 - mae: 0.1232 - mse: 0.0502 - val_loss: 0.1585 - val_accuracy: 0.8175 - val_mae: 0.2283 - val_mse: 0.1585\n",
      "Epoch 277/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9424 - mae: 0.1257 - mse: 0.0507 - val_loss: 0.1583 - val_accuracy: 0.8200 - val_mae: 0.2264 - val_mse: 0.1583\n",
      "Epoch 278/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9403 - mae: 0.1257 - mse: 0.0515 - val_loss: 0.1617 - val_accuracy: 0.8213 - val_mae: 0.2278 - val_mse: 0.1617\n",
      "Epoch 279/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9403 - mae: 0.1253 - mse: 0.0503 - val_loss: 0.1638 - val_accuracy: 0.8237 - val_mae: 0.2298 - val_mse: 0.1638\n",
      "Epoch 280/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9419 - mae: 0.1245 - mse: 0.0496 - val_loss: 0.1660 - val_accuracy: 0.8100 - val_mae: 0.2347 - val_mse: 0.1660\n",
      "Epoch 281/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9408 - mae: 0.1252 - mse: 0.0512 - val_loss: 0.1625 - val_accuracy: 0.8175 - val_mae: 0.2268 - val_mse: 0.1625\n",
      "Epoch 282/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9414 - mae: 0.1260 - mse: 0.0504 - val_loss: 0.1613 - val_accuracy: 0.8150 - val_mae: 0.2322 - val_mse: 0.1613\n",
      "Epoch 283/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9424 - mae: 0.1233 - mse: 0.0499 - val_loss: 0.1672 - val_accuracy: 0.8125 - val_mae: 0.2338 - val_mse: 0.1672\n",
      "Epoch 284/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9454 - mae: 0.1232 - mse: 0.0499 - val_loss: 0.1635 - val_accuracy: 0.8175 - val_mae: 0.2311 - val_mse: 0.1635\n",
      "Epoch 285/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9417 - mae: 0.1260 - mse: 0.0511 - val_loss: 0.1757 - val_accuracy: 0.8113 - val_mae: 0.2365 - val_mse: 0.1757\n",
      "Epoch 286/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9414 - mae: 0.1234 - mse: 0.0499 - val_loss: 0.1705 - val_accuracy: 0.8087 - val_mae: 0.2405 - val_mse: 0.1705\n",
      "Epoch 287/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9446 - mae: 0.1238 - mse: 0.0494 - val_loss: 0.1763 - val_accuracy: 0.8137 - val_mae: 0.2438 - val_mse: 0.1763\n",
      "Epoch 288/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9449 - mae: 0.1228 - mse: 0.0490 - val_loss: 0.1677 - val_accuracy: 0.8113 - val_mae: 0.2345 - val_mse: 0.1677\n",
      "Epoch 289/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9419 - mae: 0.1249 - mse: 0.0503 - val_loss: 0.1743 - val_accuracy: 0.8087 - val_mae: 0.2381 - val_mse: 0.1743\n",
      "Epoch 290/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9442 - mae: 0.1238 - mse: 0.0500 - val_loss: 0.1652 - val_accuracy: 0.8075 - val_mae: 0.2397 - val_mse: 0.1652\n",
      "Epoch 291/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9447 - mae: 0.1234 - mse: 0.0495 - val_loss: 0.1583 - val_accuracy: 0.8187 - val_mae: 0.2290 - val_mse: 0.1583\n",
      "Epoch 292/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9461 - mae: 0.1233 - mse: 0.0489 - val_loss: 0.1602 - val_accuracy: 0.8150 - val_mae: 0.2301 - val_mse: 0.1602\n",
      "Epoch 293/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9454 - mae: 0.1238 - mse: 0.0492 - val_loss: 0.1722 - val_accuracy: 0.8150 - val_mae: 0.2325 - val_mse: 0.1722\n",
      "Epoch 294/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9439 - mae: 0.1222 - mse: 0.0495 - val_loss: 0.1686 - val_accuracy: 0.8250 - val_mae: 0.2323 - val_mse: 0.1686\n",
      "Epoch 295/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9435 - mae: 0.1251 - mse: 0.0499 - val_loss: 0.1663 - val_accuracy: 0.8137 - val_mae: 0.2332 - val_mse: 0.1663\n",
      "Epoch 296/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9425 - mae: 0.1248 - mse: 0.0499 - val_loss: 0.1724 - val_accuracy: 0.8075 - val_mae: 0.2411 - val_mse: 0.1724\n",
      "Epoch 297/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9468 - mae: 0.1209 - mse: 0.0480 - val_loss: 0.1639 - val_accuracy: 0.8200 - val_mae: 0.2298 - val_mse: 0.1639\n",
      "Epoch 298/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9453 - mae: 0.1227 - mse: 0.0491 - val_loss: 0.1660 - val_accuracy: 0.8187 - val_mae: 0.2303 - val_mse: 0.1660\n",
      "Epoch 299/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9447 - mae: 0.1218 - mse: 0.0488 - val_loss: 0.1660 - val_accuracy: 0.8137 - val_mae: 0.2330 - val_mse: 0.1660\n",
      "Epoch 300/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9432 - mae: 0.1242 - mse: 0.0494 - val_loss: 0.1626 - val_accuracy: 0.8137 - val_mae: 0.2291 - val_mse: 0.1626\n",
      "Epoch 301/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9449 - mae: 0.1214 - mse: 0.0485 - val_loss: 0.1630 - val_accuracy: 0.8200 - val_mae: 0.2275 - val_mse: 0.1630\n",
      "Epoch 302/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9443 - mae: 0.1226 - mse: 0.0491 - val_loss: 0.1641 - val_accuracy: 0.8075 - val_mae: 0.2397 - val_mse: 0.1641\n",
      "Epoch 303/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9451 - mae: 0.1228 - mse: 0.0484 - val_loss: 0.1652 - val_accuracy: 0.8113 - val_mae: 0.2327 - val_mse: 0.1652\n",
      "Epoch 304/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9454 - mae: 0.1222 - mse: 0.0484 - val_loss: 0.1782 - val_accuracy: 0.8037 - val_mae: 0.2416 - val_mse: 0.1782\n",
      "Epoch 305/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9437 - mae: 0.1248 - mse: 0.0497 - val_loss: 0.1703 - val_accuracy: 0.8150 - val_mae: 0.2346 - val_mse: 0.1703\n",
      "Epoch 306/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9442 - mae: 0.1230 - mse: 0.0493 - val_loss: 0.1669 - val_accuracy: 0.8175 - val_mae: 0.2300 - val_mse: 0.1669\n",
      "Epoch 307/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9475 - mae: 0.1212 - mse: 0.0475 - val_loss: 0.1737 - val_accuracy: 0.8163 - val_mae: 0.2382 - val_mse: 0.1737\n",
      "Epoch 308/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9447 - mae: 0.1243 - mse: 0.0496 - val_loss: 0.1742 - val_accuracy: 0.8087 - val_mae: 0.2354 - val_mse: 0.1742\n",
      "Epoch 309/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9467 - mae: 0.1213 - mse: 0.0482 - val_loss: 0.1914 - val_accuracy: 0.8037 - val_mae: 0.2540 - val_mse: 0.1914\n",
      "Epoch 310/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9436 - mae: 0.1226 - mse: 0.0487 - val_loss: 0.1645 - val_accuracy: 0.8225 - val_mae: 0.2343 - val_mse: 0.1645\n",
      "Epoch 311/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9437 - mae: 0.1237 - mse: 0.0495 - val_loss: 0.1667 - val_accuracy: 0.8163 - val_mae: 0.2352 - val_mse: 0.1667\n",
      "Epoch 312/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9440 - mae: 0.1227 - mse: 0.0488 - val_loss: 0.1697 - val_accuracy: 0.8225 - val_mae: 0.2308 - val_mse: 0.1697\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9457 - mae: 0.1220 - mse: 0.0483 - val_loss: 0.1748 - val_accuracy: 0.8100 - val_mae: 0.2392 - val_mse: 0.1748\n",
      "Epoch 314/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9460 - mae: 0.1196 - mse: 0.0479 - val_loss: 0.1767 - val_accuracy: 0.8050 - val_mae: 0.2448 - val_mse: 0.1767\n",
      "Epoch 315/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9458 - mae: 0.1209 - mse: 0.0481 - val_loss: 0.1743 - val_accuracy: 0.8125 - val_mae: 0.2405 - val_mse: 0.1743\n",
      "Epoch 316/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9449 - mae: 0.1235 - mse: 0.0487 - val_loss: 0.1718 - val_accuracy: 0.8150 - val_mae: 0.2379 - val_mse: 0.1718\n",
      "Epoch 317/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9442 - mae: 0.1219 - mse: 0.0486 - val_loss: 0.1658 - val_accuracy: 0.8125 - val_mae: 0.2328 - val_mse: 0.1658\n",
      "Epoch 318/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9468 - mae: 0.1191 - mse: 0.0471 - val_loss: 0.1729 - val_accuracy: 0.8137 - val_mae: 0.2341 - val_mse: 0.1729\n",
      "Epoch 319/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9458 - mae: 0.1229 - mse: 0.0491 - val_loss: 0.1773 - val_accuracy: 0.8025 - val_mae: 0.2459 - val_mse: 0.1773\n",
      "Epoch 320/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9483 - mae: 0.1206 - mse: 0.0473 - val_loss: 0.1776 - val_accuracy: 0.8113 - val_mae: 0.2391 - val_mse: 0.1776\n",
      "Epoch 321/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9476 - mae: 0.1209 - mse: 0.0477 - val_loss: 0.1707 - val_accuracy: 0.8150 - val_mae: 0.2359 - val_mse: 0.1707\n",
      "Epoch 322/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9464 - mae: 0.1196 - mse: 0.0474 - val_loss: 0.1874 - val_accuracy: 0.8063 - val_mae: 0.2496 - val_mse: 0.1874\n",
      "Epoch 323/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9456 - mae: 0.1220 - mse: 0.0482 - val_loss: 0.1705 - val_accuracy: 0.8113 - val_mae: 0.2357 - val_mse: 0.1705\n",
      "Epoch 324/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9485 - mae: 0.1203 - mse: 0.0469 - val_loss: 0.1666 - val_accuracy: 0.8125 - val_mae: 0.2319 - val_mse: 0.1666\n",
      "Epoch 325/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9471 - mae: 0.1209 - mse: 0.0477 - val_loss: 0.1682 - val_accuracy: 0.8187 - val_mae: 0.2289 - val_mse: 0.1682\n",
      "Epoch 326/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.9457 - mae: 0.1197 - mse: 0.0475 - val_loss: 0.1810 - val_accuracy: 0.8037 - val_mae: 0.2430 - val_mse: 0.1810\n",
      "Epoch 327/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0478 - accuracy: 0.9464 - mae: 0.1216 - mse: 0.0478 - val_loss: 0.1792 - val_accuracy: 0.8125 - val_mae: 0.2399 - val_mse: 0.1792\n",
      "Epoch 328/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9460 - mae: 0.1212 - mse: 0.0474 - val_loss: 0.1746 - val_accuracy: 0.8037 - val_mae: 0.2402 - val_mse: 0.1746\n",
      "Epoch 329/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9439 - mae: 0.1216 - mse: 0.0481 - val_loss: 0.1723 - val_accuracy: 0.8125 - val_mae: 0.2362 - val_mse: 0.1723\n",
      "Epoch 330/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9467 - mae: 0.1212 - mse: 0.0478 - val_loss: 0.1742 - val_accuracy: 0.8100 - val_mae: 0.2426 - val_mse: 0.1742\n",
      "Epoch 331/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9481 - mae: 0.1206 - mse: 0.0470 - val_loss: 0.1721 - val_accuracy: 0.8200 - val_mae: 0.2374 - val_mse: 0.1721\n",
      "Epoch 332/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0469 - accuracy: 0.9487 - mae: 0.1199 - mse: 0.0469 - val_loss: 0.1813 - val_accuracy: 0.8137 - val_mae: 0.2390 - val_mse: 0.1813\n",
      "Epoch 333/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9497 - mae: 0.1198 - mse: 0.0468 - val_loss: 0.1643 - val_accuracy: 0.8163 - val_mae: 0.2319 - val_mse: 0.1643\n",
      "Epoch 334/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9463 - mae: 0.1217 - mse: 0.0479 - val_loss: 0.1759 - val_accuracy: 0.8137 - val_mae: 0.2442 - val_mse: 0.1759\n",
      "Epoch 335/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9497 - mae: 0.1210 - mse: 0.0472 - val_loss: 0.1762 - val_accuracy: 0.8137 - val_mae: 0.2437 - val_mse: 0.1762\n",
      "Epoch 336/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9479 - mae: 0.1210 - mse: 0.0474 - val_loss: 0.1716 - val_accuracy: 0.8137 - val_mae: 0.2372 - val_mse: 0.1716\n",
      "Epoch 337/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9467 - mae: 0.1213 - mse: 0.0477 - val_loss: 0.1857 - val_accuracy: 0.8063 - val_mae: 0.2438 - val_mse: 0.1857\n",
      "Epoch 338/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9483 - mae: 0.1194 - mse: 0.0463 - val_loss: 0.1642 - val_accuracy: 0.8100 - val_mae: 0.2312 - val_mse: 0.1642\n",
      "Epoch 339/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9463 - mae: 0.1212 - mse: 0.0478 - val_loss: 0.1854 - val_accuracy: 0.8125 - val_mae: 0.2408 - val_mse: 0.1854\n",
      "Epoch 340/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9479 - mae: 0.1203 - mse: 0.0469 - val_loss: 0.1732 - val_accuracy: 0.8175 - val_mae: 0.2312 - val_mse: 0.1732\n",
      "Epoch 341/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9481 - mae: 0.1186 - mse: 0.0460 - val_loss: 0.1775 - val_accuracy: 0.8050 - val_mae: 0.2459 - val_mse: 0.1775\n",
      "Epoch 342/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9464 - mae: 0.1201 - mse: 0.0471 - val_loss: 0.1764 - val_accuracy: 0.8037 - val_mae: 0.2497 - val_mse: 0.1764\n",
      "Epoch 343/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9476 - mae: 0.1209 - mse: 0.0470 - val_loss: 0.1764 - val_accuracy: 0.8125 - val_mae: 0.2370 - val_mse: 0.1764\n",
      "Epoch 344/400\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.9494 - mae: 0.1191 - mse: 0.0463 - val_loss: 0.1763 - val_accuracy: 0.8100 - val_mae: 0.2394 - val_mse: 0.1763\n",
      "Epoch 345/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9494 - mae: 0.1193 - mse: 0.0465 - val_loss: 0.1749 - val_accuracy: 0.8025 - val_mae: 0.2450 - val_mse: 0.1749\n",
      "Epoch 346/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.9499 - mae: 0.1201 - mse: 0.0464 - val_loss: 0.1728 - val_accuracy: 0.8137 - val_mae: 0.2350 - val_mse: 0.1728\n",
      "Epoch 347/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9478 - mae: 0.1196 - mse: 0.0467 - val_loss: 0.1731 - val_accuracy: 0.8163 - val_mae: 0.2343 - val_mse: 0.1731\n",
      "Epoch 348/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9485 - mae: 0.1214 - mse: 0.0472 - val_loss: 0.1721 - val_accuracy: 0.8175 - val_mae: 0.2336 - val_mse: 0.1721\n",
      "Epoch 349/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9487 - mae: 0.1193 - mse: 0.0462 - val_loss: 0.1719 - val_accuracy: 0.8100 - val_mae: 0.2407 - val_mse: 0.1719\n",
      "Epoch 350/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9492 - mae: 0.1206 - mse: 0.0470 - val_loss: 0.1743 - val_accuracy: 0.8075 - val_mae: 0.2440 - val_mse: 0.1743\n",
      "Epoch 351/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9507 - mae: 0.1188 - mse: 0.0457 - val_loss: 0.1815 - val_accuracy: 0.8037 - val_mae: 0.2478 - val_mse: 0.1815\n",
      "Epoch 352/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9475 - mae: 0.1202 - mse: 0.0468 - val_loss: 0.1842 - val_accuracy: 0.8087 - val_mae: 0.2446 - val_mse: 0.1842\n",
      "Epoch 353/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9482 - mae: 0.1208 - mse: 0.0471 - val_loss: 0.1763 - val_accuracy: 0.8125 - val_mae: 0.2420 - val_mse: 0.1763\n",
      "Epoch 354/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9486 - mae: 0.1210 - mse: 0.0474 - val_loss: 0.1713 - val_accuracy: 0.8037 - val_mae: 0.2403 - val_mse: 0.1713\n",
      "Epoch 355/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9487 - mae: 0.1190 - mse: 0.0467 - val_loss: 0.1737 - val_accuracy: 0.8000 - val_mae: 0.2444 - val_mse: 0.1737\n",
      "Epoch 356/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9501 - mae: 0.1199 - mse: 0.0463 - val_loss: 0.1681 - val_accuracy: 0.8137 - val_mae: 0.2328 - val_mse: 0.1681\n",
      "Epoch 357/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9492 - mae: 0.1167 - mse: 0.0451 - val_loss: 0.1834 - val_accuracy: 0.8150 - val_mae: 0.2485 - val_mse: 0.1834\n",
      "Epoch 358/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.9497 - mae: 0.1196 - mse: 0.0459 - val_loss: 0.1805 - val_accuracy: 0.8100 - val_mae: 0.2417 - val_mse: 0.1805\n",
      "Epoch 359/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9483 - mae: 0.1191 - mse: 0.0465 - val_loss: 0.1801 - val_accuracy: 0.8100 - val_mae: 0.2414 - val_mse: 0.1801\n",
      "Epoch 360/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9492 - mae: 0.1202 - mse: 0.0464 - val_loss: 0.1770 - val_accuracy: 0.8100 - val_mae: 0.2350 - val_mse: 0.1770\n",
      "Epoch 361/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9487 - mae: 0.1175 - mse: 0.0455 - val_loss: 0.1766 - val_accuracy: 0.8113 - val_mae: 0.2370 - val_mse: 0.1766\n",
      "Epoch 362/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9499 - mae: 0.1195 - mse: 0.0463 - val_loss: 0.1756 - val_accuracy: 0.8075 - val_mae: 0.2406 - val_mse: 0.1756\n",
      "Epoch 363/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9469 - mae: 0.1208 - mse: 0.0470 - val_loss: 0.1846 - val_accuracy: 0.8025 - val_mae: 0.2469 - val_mse: 0.1846\n",
      "Epoch 364/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9499 - mae: 0.1193 - mse: 0.0465 - val_loss: 0.1771 - val_accuracy: 0.8063 - val_mae: 0.2394 - val_mse: 0.1771\n",
      "Epoch 365/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9489 - mae: 0.1182 - mse: 0.0458 - val_loss: 0.1752 - val_accuracy: 0.8125 - val_mae: 0.2379 - val_mse: 0.1752\n",
      "Epoch 366/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9508 - mae: 0.1199 - mse: 0.0463 - val_loss: 0.1770 - val_accuracy: 0.8100 - val_mae: 0.2381 - val_mse: 0.1770\n",
      "Epoch 367/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9494 - mae: 0.1180 - mse: 0.0454 - val_loss: 0.1851 - val_accuracy: 0.8025 - val_mae: 0.2443 - val_mse: 0.1851\n",
      "Epoch 368/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9500 - mae: 0.1189 - mse: 0.0457 - val_loss: 0.1846 - val_accuracy: 0.8075 - val_mae: 0.2477 - val_mse: 0.1846\n",
      "Epoch 369/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9508 - mae: 0.1185 - mse: 0.0450 - val_loss: 0.1685 - val_accuracy: 0.8150 - val_mae: 0.2378 - val_mse: 0.1685\n",
      "Epoch 370/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9511 - mae: 0.1188 - mse: 0.0459 - val_loss: 0.1779 - val_accuracy: 0.8113 - val_mae: 0.2426 - val_mse: 0.1779\n",
      "Epoch 371/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9486 - mae: 0.1200 - mse: 0.0462 - val_loss: 0.1683 - val_accuracy: 0.8163 - val_mae: 0.2314 - val_mse: 0.1683\n",
      "Epoch 372/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9511 - mae: 0.1193 - mse: 0.0458 - val_loss: 0.1766 - val_accuracy: 0.8075 - val_mae: 0.2414 - val_mse: 0.1766\n",
      "Epoch 373/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.9493 - mae: 0.1193 - mse: 0.0462 - val_loss: 0.1752 - val_accuracy: 0.8050 - val_mae: 0.2401 - val_mse: 0.1752\n",
      "Epoch 374/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9507 - mae: 0.1185 - mse: 0.0458 - val_loss: 0.1794 - val_accuracy: 0.8013 - val_mae: 0.2474 - val_mse: 0.1794\n",
      "Epoch 375/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9521 - mae: 0.1181 - mse: 0.0451 - val_loss: 0.1725 - val_accuracy: 0.8150 - val_mae: 0.2358 - val_mse: 0.1725\n",
      "Epoch 376/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9499 - mae: 0.1168 - mse: 0.0448 - val_loss: 0.1792 - val_accuracy: 0.8100 - val_mae: 0.2404 - val_mse: 0.1792\n",
      "Epoch 377/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9497 - mae: 0.1180 - mse: 0.0451 - val_loss: 0.1853 - val_accuracy: 0.8013 - val_mae: 0.2510 - val_mse: 0.1853\n",
      "Epoch 378/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9517 - mae: 0.1167 - mse: 0.0445 - val_loss: 0.1757 - val_accuracy: 0.8087 - val_mae: 0.2428 - val_mse: 0.1757\n",
      "Epoch 379/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9510 - mae: 0.1173 - mse: 0.0455 - val_loss: 0.1816 - val_accuracy: 0.8063 - val_mae: 0.2449 - val_mse: 0.1816\n",
      "Epoch 380/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0455 - accuracy: 0.9510 - mae: 0.1195 - mse: 0.0455 - val_loss: 0.1764 - val_accuracy: 0.8163 - val_mae: 0.2355 - val_mse: 0.1764\n",
      "Epoch 381/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9499 - mae: 0.1176 - mse: 0.0452 - val_loss: 0.1786 - val_accuracy: 0.8087 - val_mae: 0.2380 - val_mse: 0.1786\n",
      "Epoch 382/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9494 - mae: 0.1182 - mse: 0.0453 - val_loss: 0.1704 - val_accuracy: 0.8087 - val_mae: 0.2400 - val_mse: 0.1704\n",
      "Epoch 383/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9508 - mae: 0.1170 - mse: 0.0445 - val_loss: 0.1770 - val_accuracy: 0.8113 - val_mae: 0.2375 - val_mse: 0.1770\n",
      "Epoch 384/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9511 - mae: 0.1184 - mse: 0.0452 - val_loss: 0.1792 - val_accuracy: 0.8025 - val_mae: 0.2417 - val_mse: 0.1792\n",
      "Epoch 385/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9490 - mae: 0.1171 - mse: 0.0448 - val_loss: 0.1753 - val_accuracy: 0.8063 - val_mae: 0.2372 - val_mse: 0.1753\n",
      "Epoch 386/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0461 - accuracy: 0.9493 - mae: 0.1196 - mse: 0.0461 - val_loss: 0.1756 - val_accuracy: 0.8025 - val_mae: 0.2432 - val_mse: 0.1756\n",
      "Epoch 387/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.9524 - mae: 0.1172 - mse: 0.0445 - val_loss: 0.1763 - val_accuracy: 0.8113 - val_mae: 0.2372 - val_mse: 0.1763\n",
      "Epoch 388/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9513 - mae: 0.1167 - mse: 0.0447 - val_loss: 0.1702 - val_accuracy: 0.8125 - val_mae: 0.2355 - val_mse: 0.1702\n",
      "Epoch 389/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0453 - accuracy: 0.9508 - mae: 0.1179 - mse: 0.0453 - val_loss: 0.1768 - val_accuracy: 0.8125 - val_mae: 0.2401 - val_mse: 0.1768\n",
      "Epoch 390/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.9501 - mae: 0.1179 - mse: 0.0450 - val_loss: 0.1799 - val_accuracy: 0.8087 - val_mae: 0.2376 - val_mse: 0.1799\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9525 - mae: 0.1171 - mse: 0.0439 - val_loss: 0.1752 - val_accuracy: 0.8163 - val_mae: 0.2338 - val_mse: 0.1752\n",
      "Epoch 392/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9507 - mae: 0.1153 - mse: 0.0444 - val_loss: 0.1782 - val_accuracy: 0.8137 - val_mae: 0.2391 - val_mse: 0.1782\n",
      "Epoch 393/400\n",
      "225/225 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.9526 - mae: 0.1174 - mse: 0.0445 - val_loss: 0.1805 - val_accuracy: 0.8100 - val_mae: 0.2396 - val_mse: 0.1805\n",
      "Epoch 394/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9528 - mae: 0.1166 - mse: 0.0440 - val_loss: 0.1797 - val_accuracy: 0.8113 - val_mae: 0.2430 - val_mse: 0.1797\n",
      "Epoch 395/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9522 - mae: 0.1163 - mse: 0.0440 - val_loss: 0.1803 - val_accuracy: 0.8087 - val_mae: 0.2458 - val_mse: 0.1803\n",
      "Epoch 396/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9510 - mae: 0.1185 - mse: 0.0451 - val_loss: 0.1687 - val_accuracy: 0.8163 - val_mae: 0.2325 - val_mse: 0.1687\n",
      "Epoch 397/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9507 - mae: 0.1182 - mse: 0.0452 - val_loss: 0.1888 - val_accuracy: 0.8037 - val_mae: 0.2519 - val_mse: 0.1888\n",
      "Epoch 398/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9506 - mae: 0.1183 - mse: 0.0452 - val_loss: 0.1721 - val_accuracy: 0.8037 - val_mae: 0.2364 - val_mse: 0.1721\n",
      "Epoch 399/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9518 - mae: 0.1173 - mse: 0.0444 - val_loss: 0.1874 - val_accuracy: 0.8037 - val_mae: 0.2501 - val_mse: 0.1874\n",
      "Epoch 400/400\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9529 - mae: 0.1158 - mse: 0.0442 - val_loss: 0.1734 - val_accuracy: 0.8125 - val_mae: 0.2406 - val_mse: 0.1734\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=400, validation_split = 0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.816389\n",
       "1      0.848472\n",
       "2      0.857500\n",
       "3      0.859861\n",
       "4      0.859028\n",
       "         ...   \n",
       "395    0.950972\n",
       "396    0.950694\n",
       "397    0.950556\n",
       "398    0.951806\n",
       "399    0.952917\n",
       "Name: accuracy, Length: 400, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hist.history)[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13bd36f40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend((\"train\" , \"valid\") , loc =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision(thresholds=0.5)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = []\n",
    "for val in y_pred:\n",
    "    if val < 0.5:\n",
    "        y_pred2.append(0)\n",
    "    else:\n",
    "        y_pred2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1444,  120],\n",
       "       [ 252,  184]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I found that if we run the trianing process several times we will have better accurancy of the model, i think the model is learning every time that we run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
